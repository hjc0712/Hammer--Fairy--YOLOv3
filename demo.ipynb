{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing object detection:\n",
      "\t+ Batch 0, Inference Time: 0:00:00.047660\n",
      "\t+ Batch 1, Inference Time: 0:00:00.037917\n",
      "\t+ Batch 2, Inference Time: 0:00:00.067192\n",
      "\t+ Batch 3, Inference Time: 0:00:00.038191\n",
      "\t+ Batch 4, Inference Time: 0:00:00.053498\n",
      "\t+ Batch 5, Inference Time: 0:00:00.033658\n",
      "\t+ Batch 6, Inference Time: 0:00:00.065203\n",
      "\t+ Batch 7, Inference Time: 0:00:00.045006\n",
      "\t+ Batch 8, Inference Time: 0:00:00.059300\n",
      "\t+ Batch 9, Inference Time: 0:00:00.040758\n",
      "\t+ Batch 10, Inference Time: 0:00:00.061528\n",
      "\t+ Batch 11, Inference Time: 0:00:00.082270\n",
      "\t+ Batch 12, Inference Time: 0:00:00.044135\n",
      "\t+ Batch 13, Inference Time: 0:00:00.076204\n",
      "\t+ Batch 14, Inference Time: 0:00:00.032284\n",
      "\t+ Batch 15, Inference Time: 0:00:00.076737\n",
      "\t+ Batch 16, Inference Time: 0:00:00.036421\n",
      "\t+ Batch 17, Inference Time: 0:00:00.057090\n",
      "\t+ Batch 18, Inference Time: 0:00:00.035594\n",
      "\t+ Batch 19, Inference Time: 0:00:00.059728\n",
      "\t+ Batch 20, Inference Time: 0:00:00.034189\n",
      "\t+ Batch 21, Inference Time: 0:00:00.057678\n",
      "\t+ Batch 22, Inference Time: 0:00:00.032246\n",
      "\t+ Batch 23, Inference Time: 0:00:00.070892\n",
      "\t+ Batch 24, Inference Time: 0:00:00.046890\n",
      "\t+ Batch 25, Inference Time: 0:00:00.061319\n",
      "\t+ Batch 26, Inference Time: 0:00:00.033144\n",
      "\t+ Batch 27, Inference Time: 0:00:00.066960\n",
      "\t+ Batch 28, Inference Time: 0:00:00.036689\n",
      "\t+ Batch 29, Inference Time: 0:00:00.071732\n",
      "\t+ Batch 30, Inference Time: 0:00:00.032544\n",
      "\t+ Batch 31, Inference Time: 0:00:00.051753\n",
      "\t+ Batch 32, Inference Time: 0:00:00.031962\n",
      "\t+ Batch 33, Inference Time: 0:00:00.082794\n",
      "\t+ Batch 34, Inference Time: 0:00:00.038917\n",
      "\t+ Batch 35, Inference Time: 0:00:00.055599\n",
      "\t+ Batch 36, Inference Time: 0:00:00.036586\n",
      "\t+ Batch 37, Inference Time: 0:00:00.064397\n",
      "\t+ Batch 38, Inference Time: 0:00:00.031476\n",
      "\t+ Batch 39, Inference Time: 0:00:00.077007\n",
      "\t+ Batch 40, Inference Time: 0:00:00.044460\n",
      "\t+ Batch 41, Inference Time: 0:00:00.045727\n",
      "\t+ Batch 42, Inference Time: 0:00:00.075486\n",
      "\t+ Batch 43, Inference Time: 0:00:00.038982\n",
      "\t+ Batch 44, Inference Time: 0:00:00.034533\n",
      "\t+ Batch 45, Inference Time: 0:00:00.050300\n",
      "\t+ Batch 46, Inference Time: 0:00:00.037783\n",
      "\t+ Batch 47, Inference Time: 0:00:00.055811\n",
      "\t+ Batch 48, Inference Time: 0:00:00.034144\n",
      "\t+ Batch 49, Inference Time: 0:00:00.078353\n",
      "\t+ Batch 50, Inference Time: 0:00:00.039707\n",
      "\t+ Batch 51, Inference Time: 0:00:00.042918\n",
      "\t+ Batch 52, Inference Time: 0:00:00.035465\n",
      "\t+ Batch 53, Inference Time: 0:00:00.053232\n",
      "\t+ Batch 54, Inference Time: 0:00:00.032091\n",
      "\t+ Batch 55, Inference Time: 0:00:00.068723\n",
      "\t+ Batch 56, Inference Time: 0:00:00.044419\n",
      "\t+ Batch 57, Inference Time: 0:00:00.064785\n",
      "\t+ Batch 58, Inference Time: 0:00:00.037045\n",
      "\t+ Batch 59, Inference Time: 0:00:00.065507\n",
      "\t+ Batch 60, Inference Time: 0:00:00.032797\n",
      "\t+ Batch 61, Inference Time: 0:00:00.066869\n",
      "\t+ Batch 62, Inference Time: 0:00:00.037394\n",
      "\t+ Batch 63, Inference Time: 0:00:00.069265\n",
      "\t+ Batch 64, Inference Time: 0:00:00.041122\n",
      "\t+ Batch 65, Inference Time: 0:00:00.053312\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.ticker import NullLocator\n",
    "\n",
    "\n",
    "class opt:\n",
    "    image_folder = \"data/samples\"\n",
    "    model_def = \"config/yolov3-custom.cfg\"\n",
    "    weights_path = \"checkpoints_voc/yolov3_ckpt_309.pth\"\n",
    "    class_path = \"config/voc.txt\"\n",
    "    conf_thres = 0.8\n",
    "    nms_thres = 0.4\n",
    "    batch_size = 1\n",
    "    img_size = 416\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "model = Darknet(opt.model_def, img_size=opt.img_size).to(device)\n",
    "\n",
    "if opt.weights_path.endswith(\".weights\"):\n",
    "    model.load_darknet_weights(opt.weights_path)\n",
    "else:\n",
    "    model.load_state_dict(torch.load(opt.weights_path))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    ImageFolder(opt.image_folder, img_size=opt.img_size),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "classes = load_classes(opt.class_path)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "imgs = []\n",
    "img_detections = []\n",
    "\n",
    "print(\"\\nPerforming object detection:\")\n",
    "prev_time = time.time()\n",
    "for batch_i, (img_paths, input_imgs) in enumerate(dataloader):\n",
    "    input_imgs = Variable(input_imgs.type(Tensor))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detections = model(input_imgs)\n",
    "        detections = non_max_suppression(detections, opt.conf_thres, opt.nms_thres)\n",
    "\n",
    "    current_time = time.time()\n",
    "    inference_time = datetime.timedelta(seconds=current_time - prev_time)\n",
    "    prev_time = current_time\n",
    "    print(\"\\t+ Batch %d, Inference Time: %s\" % (batch_i, inference_time))\n",
    "\n",
    "    imgs.extend(img_paths)\n",
    "    img_detections.extend(detections)\n",
    "\n",
    "cmap = plt.get_cmap(\"tab20b\")\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 20)]\n",
    "\n",
    "print(\"\\nSaving images:\")\n",
    "for img_i, (path, detections) in enumerate(zip(imgs, img_detections)):\n",
    "\n",
    "    print(\"(%d) Image: '%s'\" % (img_i, path))\n",
    "\n",
    "    img = np.array(Image.open(path))\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "\n",
    "    if detections is not None:\n",
    "        detections = rescale_boxes(detections, opt.img_size, img.shape[:2])\n",
    "        unique_labels = detections[:, -1].cpu().unique()\n",
    "        n_cls_preds = len(unique_labels)\n",
    "        bbox_colors = random.sample(colors, n_cls_preds)\n",
    "        for x1, y1, x2, y2, conf, cls_conf, cls_pred in detections:\n",
    "\n",
    "            print(\"\\t+ Label: %s, Conf: %.5f\" % (classes[int(cls_pred)], cls_conf.item()))\n",
    "\n",
    "            box_w = x2 - x1\n",
    "            box_h = y2 - y1\n",
    "\n",
    "            color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n",
    "            bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor=\"none\")\n",
    "            ax.add_patch(bbox)\n",
    "\n",
    "            plt.text(\n",
    "                x1,\n",
    "                y1,\n",
    "                s=classes[int(cls_pred)],\n",
    "                color=\"white\",\n",
    "                verticalalignment=\"top\",\n",
    "                bbox={\"color\": color, \"pad\": 0},\n",
    "            )\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "    filename = path.split(\"/\")[-1].split(\".\")[0]\n",
    "    plt.savefig(f\"output/{filename}.png\", bbox_inches=\"tight\", pad_inches=0.0)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
